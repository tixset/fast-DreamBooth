{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qEsNHTtVlbkV"
   },
   "source": [
    "# üöÄ Fast DreamBooth - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º\n",
    "\n",
    "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**\n",
    "1. ‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É \"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Google Drive\"\n",
    "2. ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —è—á–µ–π–∫–µ \"–ù–ê–°–¢–†–û–ô–ö–ò\"\n",
    "3. üì∏ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≤ —è—á–µ–π–∫–µ \"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\n",
    "4. ‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —è—á–µ–π–∫–∏ (Runtime ‚Üí Run after / Ctrl+F10)\n",
    "5. ‚òï –ì–æ—Ç–æ–≤–æ! –ñ–¥–∏—Ç–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "---\n",
    "\n",
    "**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ì–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å .ckpt –≤ Google Drive —á–µ—Ä–µ–∑ 15-30 –º–∏–Ω—É—Ç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã –ö—Ä–∞—Ç–∫–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è\n",
    "\n",
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–¥–æ –∑–∞–ø—É—Å–∫–∞ –Ω–æ—É—Ç–±—É–∫–∞)\n",
    "1. **–°–æ–±–µ—Ä–∏—Ç–µ 10-20 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π** –æ–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞/–æ–±—ä–µ–∫—Ç–∞/—Å—Ç–∏–ª—è\n",
    "   - –ß—ë—Ç–∫–∏–µ, —Ö–æ—Ä–æ—à–µ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ\n",
    "   - –†–∞–∑–Ω—ã–µ —Ä–∞–∫—É—Ä—Å—ã –∏ –ø–æ–∑—ã\n",
    "   \n",
    "2. **–ü–µ—Ä–µ–∏–º–µ–Ω—É–π—Ç–µ –í–°–ï —Ñ–∞–π–ª—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º:**\n",
    "   - Windows: –í—ã–¥–µ–ª–∏—Ç–µ –≤—Å–µ ‚Üí F2 ‚Üí –≤–≤–µ–¥–∏—Ç–µ `sksper` ‚Üí Enter\n",
    "   - –†–µ–∑—É–ª—å—Ç–∞—Ç: `sksper (1).jpg`, `sksper (2).jpg`, `sksper (3).jpg`...\n",
    "   - ‚ö†Ô∏è **–í–ê–ñ–ù–û:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–ª–æ–≤–∞: `sksper`, `ohwx`, `zkz`\n",
    "   - ‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞: `person`, `photo`, `john`\n",
    "\n",
    "### üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç - 4 —à–∞–≥–∞ –∫ –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏!\n",
    "\n",
    "**–®–∞–≥ 1: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Google Drive**\n",
    "- ‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É \"üìÅ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Google Drive\"\n",
    "- –†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ Google Drive\n",
    "\n",
    "**–®–∞–≥ 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∏**\n",
    "- ‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É \"‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò\"\n",
    "- –£–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: `my_model_2024`)\n",
    "- –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –æ–±—É—á–µ–Ω–∏—è: –õ–∏—Ü–æ/–ü–µ—Ä—Å–æ–Ω–∞, –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å –∏–ª–∏ –û–±—ä–µ–∫—Ç\n",
    "- –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ—è—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!\n",
    "\n",
    "**–®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π**\n",
    "- ‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É \"üì∏ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\n",
    "- Choose Files ‚Üí –≤—ã–±–µ—Ä–∏—Ç–µ –≤—Å–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ç–æ\n",
    "- –î–æ–∂–¥–∏—Ç–µ—Å—å: ‚úÖ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–ì–†–£–ñ–ï–ù–´\n",
    "\n",
    "**–®–∞–≥ 4: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ**\n",
    "- ‚ñ∂Ô∏è Runtime ‚Üí Run after (Ctrl+F10)\n",
    "- ‚òï –ñ–¥–∏—Ç–µ 15-30 –º–∏–Ω—É—Ç\n",
    "- –ú–æ–∂–µ—Ç–µ —É–π—Ç–∏ –æ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞!\n",
    "\n",
    "### üéØ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –Ω–æ—É—Ç–±—É–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n",
    "- ‚úÖ –°–æ–∑–¥–∞—ë—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –Ω–∞ Google Drive\n",
    "- ‚úÖ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (diffusers, accelerate, xformers)\n",
    "- ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å SD 1.5 (–∏–ª–∏ –¥—Ä—É–≥—É—é –ø–æ –≤—ã–±–æ—Ä—É)\n",
    "- ‚úÖ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≤–∞—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "- ‚úÖ –û–±—É—á–∞–µ—Ç Text Encoder (3-7 –º–∏–Ω—É—Ç)\n",
    "- ‚úÖ –û–±—É—á–∞–µ—Ç UNet (15-25 –º–∏–Ω—É—Ç)\n",
    "- ‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç .ckpt\n",
    "- ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ Google Drive\n",
    "\n",
    "### üì• –†–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "**–ì–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å:** `Google Drive ‚Üí Fast-Dreambooth ‚Üí Sessions ‚Üí [–Ω–∞–∑–≤–∞–Ω–∏–µ] ‚Üí [–Ω–∞–∑–≤–∞–Ω–∏–µ].ckpt`\n",
    "\n",
    "**–†–∞–∑–º–µ—Ä:** ~2-4 GB\n",
    "\n",
    "**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**\n",
    "```\n",
    "sksper person, professional portrait, high quality\n",
    "sksper person wearing sunglasses, outdoor\n",
    "sksper person as a superhero, digital art\n",
    "```\n",
    "(–ó–∞–º–µ–Ω–∏—Ç–µ `sksper` –Ω–∞ –≤–∞—à –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä!)\n",
    "\n",
    "### üìö –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\n",
    "–°–º–æ—Ç—Ä–∏—Ç–µ [DETAILED_GUIDE.md](DETAILED_GUIDE.md) –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4Bae3VP6UsE"
   },
   "outputs": [],
   "source": [
    "#@title üìÅ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "print('‚úì Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–¥–µ—Å—å { display-mode: \"form\" }\n",
    "\n",
    "# ========================================\n",
    "# –û–°–ù–û–í–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò\n",
    "# ========================================\n",
    "\n",
    "#@markdown ### üìù –ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏\n",
    "Session_Name = \"sksper_model\" #@param {type:\"string\"}\n",
    "#@markdown –ò–º—è –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ (–ª–∞—Ç–∏–Ω–∏—Ü–∞, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üéØ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å\n",
    "\n",
    "Model_Version = \"1.5\" #@param [\"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
    "#@markdown –í–µ—Ä—Å–∏—è Stable Diffusion\n",
    "\n",
    "Path_to_HuggingFace = \"\" #@param {type:\"string\"}\n",
    "#@markdown (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ú–æ–¥–µ–ª—å —Å HuggingFace, –Ω–∞–ø—Ä–∏–º–µ—Ä: runwayml/stable-diffusion-v1-5\n",
    "\n",
    "MODEL_PATH = \"\" #@param {type:\"string\"}\n",
    "#@markdown (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ .ckpt/.safetensors\n",
    "\n",
    "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
    "#@markdown (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å (Civitai, Google Drive)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üé® –¢–∏–ø –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "Training_Type = \"–õ–∏—Ü–æ/–ü–µ—Ä—Å–æ–Ω–∞\" #@param [\"–õ–∏—Ü–æ/–ü–µ—Ä—Å–æ–Ω–∞\", \"–•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å\", \"–û–±—ä–µ–∫—Ç\"]\n",
    "#@markdown –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ)\n",
    "\n",
    "#@markdown **UNet (–æ—Å–Ω–æ–≤–Ω–∞—è —Å–µ—Ç—å)**\n",
    "UNet_Training_Steps = 1500 #@param {type:\"number\"}\n",
    "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\", \"1e-6\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown **Text Encoder (–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Ç–µ–∫—Å—Ç–∞)**\n",
    "Text_Encoder_Training_Steps = 350 #@param {type:\"number\"}\n",
    "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏**\n",
    "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
    "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
    "Auto_Resize_Images = True #@param {type:\"boolean\"}\n",
    "External_Captions = False #@param {type:\"boolean\"}\n",
    "Offset_Noise = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π**\n",
    "Save_Checkpoint_Every_n_Steps = True #@param {type:\"boolean\"}\n",
    "Save_Checkpoint_Every = 500 #@param {type:\"number\"}\n",
    "Start_saving_from_the_step = 500 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è**\n",
    "Disconnect_after_training = False #@param {type:\"boolean\"}\n",
    "#@markdown –û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç Colab –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "# ========================================\n",
    "# –í–ê–õ–ò–î–ê–¶–ò–Ø –í–•–û–î–ù–´–• –î–ê–ù–ù–´–•\n",
    "# ========================================\n",
    "\n",
    "import re\n",
    "\n",
    "# –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Å–µ—Å—Å–∏–∏\n",
    "Session_Name = Session_Name.strip().replace(\" \", \"_\")\n",
    "if not re.match(r'^[a-zA-Z0-9_-]+$', Session_Name):\n",
    "    print(\"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò–º—è —Å–µ—Å—Å–∏–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã\")\n",
    "    print(\"–†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ: –ª–∞—Ç–∏–Ω–∏—Ü–∞, —Ü–∏—Ñ—Ä—ã, _, -\")\n",
    "    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    Session_Name = re.sub(r'[^a-zA-Z0-9_-]', '_', Session_Name)\n",
    "    print(f\"‚úì –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞: {Session_Name}\")\n",
    "\n",
    "if len(Session_Name) < 3:\n",
    "    print(\"‚ùå –û–®–ò–ë–ö–ê: –ò–º—è —Å–µ—Å—Å–∏–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞)\")\n",
    "    raise ValueError(\"Session name too short\")\n",
    "\n",
    "if len(Session_Name) > 50:\n",
    "    print(\"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò–º—è —Å–µ—Å—Å–∏–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ\")\n",
    "    Session_Name = Session_Name[:50]\n",
    "    print(f\"‚úì –û–±—Ä–µ–∑–∞–Ω–æ –¥–æ: {Session_Name}\")\n",
    "\n",
    "# ========================================\n",
    "# –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê –ü–û –¢–ò–ü–£\n",
    "# ========================================\n",
    "\n",
    "if Training_Type == \"–•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å\":\n",
    "    UNet_Training_Steps = 2500 if UNet_Training_Steps == 1500 else UNet_Training_Steps\n",
    "    UNet_Learning_Rate = 1e-6 if UNet_Learning_Rate == 2e-6 else UNet_Learning_Rate\n",
    "    Text_Encoder_Training_Steps = 500 if Text_Encoder_Training_Steps == 350 else Text_Encoder_Training_Steps\n",
    "    Text_Encoder_Learning_Rate = 8e-7 if Text_Encoder_Learning_Rate == 1e-6 else Text_Encoder_Learning_Rate\n",
    "    External_Captions = True\n",
    "    Offset_Noise = True\n",
    "    print(\"üé® –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å—Ç–∏–ª—è\")\n",
    "elif Training_Type == \"–û–±—ä–µ–∫—Ç\":\n",
    "    UNet_Training_Steps = 1200 if UNet_Training_Steps == 1500 else UNet_Training_Steps\n",
    "    Text_Encoder_Training_Steps = 300 if Text_Encoder_Training_Steps == 350 else Text_Encoder_Training_Steps\n",
    "    print(\"üì¶ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞\")\n",
    "else:\n",
    "    print(\"üë§ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª–∏—Ü–∞/–ø–µ—Ä—Å–æ–Ω—ã\")\n",
    "\n",
    "# ========================================\n",
    "# –°–û–ó–î–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –î–ò–†–ï–ö–¢–û–†–ò–ô\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "WORKSPACE = '/content/gdrive/MyDrive/Fast-Dreambooth'\n",
    "SESSION_DIR = WORKSPACE + '/Sessions/' + Session_Name\n",
    "INSTANCE_DIR = SESSION_DIR + '/instance_images'\n",
    "CAPTIONS_DIR = SESSION_DIR + '/captions'\n",
    "OUTPUT_DIR = \"/content/models/\" + Session_Name\n",
    "\n",
    "os.makedirs(INSTANCE_DIR, exist_ok=True)\n",
    "os.makedirs(CAPTIONS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì –°–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞: {Session_Name}\")\n",
    "print(f\"‚úì –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≥–æ—Ç–æ–≤—ã\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"–ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"–°–µ—Å—Å–∏—è: {Session_Name}\")\n",
    "print(f\"UNet —à–∞–≥–∏: {UNet_Training_Steps}, LR: {UNet_Learning_Rate}\")\n",
    "print(f\"Text Encoder —à–∞–≥–∏: {Text_Encoder_Training_Steps}, LR: {Text_Encoder_Learning_Rate}\")\n",
    "print(f\"–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {Resolution}\")\n",
    "print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: {Save_Checkpoint_Every} —à–∞–≥–æ–≤\" if Save_Checkpoint_Every_n_Steps else \"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–¥–µ—Å—å { display-mode: \"form\" }\n",
    "\n",
    "# ========================================\n",
    "# –û–°–ù–û–í–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò\n",
    "# ========================================\n",
    "\n",
    "#@markdown ### üìù –ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏\n",
    "Session_Name = \"sksper_model\" #@param {type:\"string\"}\n",
    "#@markdown –ò–º—è –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ (–ª–∞—Ç–∏–Ω–∏—Ü–∞, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üéØ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å\n",
    "\n",
    "Model_Version = \"1.5\" #@param [\"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
    "#@markdown –í–µ—Ä—Å–∏—è Stable Diffusion\n",
    "\n",
    "Path_to_HuggingFace = \"\" #@param {type:\"string\"}\n",
    "#@markdown (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ú–æ–¥–µ–ª—å —Å HuggingFace, –Ω–∞–ø—Ä–∏–º–µ—Ä: runwayml/stable-diffusion-v1-5\n",
    "\n",
    "MODEL_PATH = \"\" #@param {type:\"string\"}\n",
    "#@markdown (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ .ckpt/.safetensors\n",
    "\n",
    "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
    "#@markdown (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å (Civitai, Google Drive)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üé® –¢–∏–ø –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "Training_Type = \"–õ–∏—Ü–æ/–ü–µ—Ä—Å–æ–Ω–∞\" #@param [\"–õ–∏—Ü–æ/–ü–µ—Ä—Å–æ–Ω–∞\", \"–•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å\", \"–û–±—ä–µ–∫—Ç\"]\n",
    "#@markdown –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ)\n",
    "\n",
    "#@markdown **UNet (–æ—Å–Ω–æ–≤–Ω–∞—è —Å–µ—Ç—å)**\n",
    "UNet_Training_Steps = 1500 #@param {type:\"number\"}\n",
    "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\", \"1e-6\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown **Text Encoder (–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Ç–µ–∫—Å—Ç–∞)**\n",
    "Text_Encoder_Training_Steps = 350 #@param {type:\"number\"}\n",
    "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏**\n",
    "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
    "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
    "Smart_Crop_images = True #@param {type:\"boolean\"}\n",
    "External_Captions = False #@param {type:\"boolean\"}\n",
    "Offset_Noise = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π**\n",
    "Save_Checkpoint_Every_n_Steps = True #@param {type:\"boolean\"}\n",
    "Save_Checkpoint_Every = 500 #@param {type:\"number\"}\n",
    "Start_saving_from_the_step = 500 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è**\n",
    "Disconnect_after_training = False #@param {type:\"boolean\"}\n",
    "#@markdown –û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç Colab –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "# ========================================\n",
    "# –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê –ü–û –¢–ò–ü–£\n",
    "# ========================================\n",
    "\n",
    "if Training_Type == \"–•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å\":\n",
    "    UNet_Training_Steps = 2500 if UNet_Training_Steps == 1500 else UNet_Training_Steps\n",
    "    UNet_Learning_Rate = 1e-6 if UNet_Learning_Rate == 2e-6 else UNet_Learning_Rate\n",
    "    Text_Encoder_Training_Steps = 500 if Text_Encoder_Training_Steps == 350 else Text_Encoder_Training_Steps\n",
    "    Text_Encoder_Learning_Rate = 8e-7 if Text_Encoder_Learning_Rate == 1e-6 else Text_Encoder_Learning_Rate\n",
    "    External_Captions = True\n",
    "    Offset_Noise = True\n",
    "    print(\"üé® –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å—Ç–∏–ª—è\")\n",
    "elif Training_Type == \"–û–±—ä–µ–∫—Ç\":\n",
    "    UNet_Training_Steps = 1200 if UNet_Training_Steps == 1500 else UNet_Training_Steps\n",
    "    Text_Encoder_Training_Steps = 300 if Text_Encoder_Training_Steps == 350 else Text_Encoder_Training_Steps\n",
    "    print(\"üì¶ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞\")\n",
    "else:\n",
    "    print(\"üë§ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª–∏—Ü–∞/–ø–µ—Ä—Å–æ–Ω—ã\")\n",
    "\n",
    "# ========================================\n",
    "# –°–û–ó–î–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –î–ò–†–ï–ö–¢–û–†–ò–ô\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "WORKSPACE = '/content/gdrive/MyDrive/Fast-Dreambooth'\n",
    "Session_Name = Session_Name.replace(\" \", \"_\")\n",
    "SESSION_DIR = WORKSPACE + '/Sessions/' + Session_Name\n",
    "INSTANCE_DIR = SESSION_DIR + '/instance_images'\n",
    "CAPTIONS_DIR = SESSION_DIR + '/captions'\n",
    "OUTPUT_DIR = \"/content/models/\" + Session_Name\n",
    "\n",
    "os.makedirs(INSTANCE_DIR, exist_ok=True)\n",
    "os.makedirs(CAPTIONS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì –°–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞: {Session_Name}\")\n",
    "print(f\"‚úì –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≥–æ—Ç–æ–≤—ã\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"–ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"–°–µ—Å—Å–∏—è: {Session_Name}\")\n",
    "print(f\"UNet —à–∞–≥–∏: {UNet_Training_Steps}, LR: {UNet_Learning_Rate}\")\n",
    "print(f\"Text Encoder —à–∞–≥–∏: {Text_Encoder_Training_Steps}, LR: {Text_Encoder_Learning_Rate}\")\n",
    "print(f\"–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {Resolution}\")\n",
    "print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: {Save_Checkpoint_Every} —à–∞–≥–æ–≤\" if Save_Checkpoint_Every_n_Steps else \"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì∏ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è { display-mode: \"form\" }\n",
    "\n",
    "import shutil\n",
    "from google.colab import files\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üì∏ –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ –°–µ—Å—Å–∏—è: {Session_Name}\")\n",
    "print(f\"üìê –†–∞–∑–º–µ—Ä: {Crop_size}x{Crop_size}\")\n",
    "print(f\"‚úÇÔ∏è  –ê–≤—Ç–æ-—Ä–µ—Å–∞–π–∑: {'–í–∫–ª—é—á–µ–Ω' if Auto_Resize_Images else '–í—ã–∫–ª—é—á–µ–Ω'}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚¨áÔ∏è  –ó–ê–ì–†–£–ó–ò–¢–ï –í–ê–®–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø\")\n",
    "print(\"-\"*60)\n",
    "print(\"‚ö†Ô∏è  –í–ê–ñ–ù–û: –í—Å–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω—ã!\")\n",
    "print(\"–ü—Ä–∏–º–µ—Ä: sksper (1).jpg, sksper (2).jpg, sksper (3).jpg\")\n",
    "print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    print(\"\\n‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")\n",
    "    print(\"–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É.\")\n",
    "    raise Exception(\"No files uploaded\")\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "caption_files = []\n",
    "image_files = []\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    if filename.split(\".\")[-1].lower() == \"txt\":\n",
    "        shutil.move(filename, CAPTIONS_DIR)\n",
    "        caption_files.append(filename)\n",
    "    else:\n",
    "        image_files.append(filename)\n",
    "\n",
    "print(f\"\\n‚åõ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\")\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "processed_count = 0\n",
    "for filename in tqdm(image_files, bar_format='  |{bar:20}| {n_fmt}/{total_fmt} –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ', ncols=70):\n",
    "    shutil.move(filename, INSTANCE_DIR)\n",
    "    extension = filename.split(\".\")[-1]\n",
    "    new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
    "    \n",
    "    if Auto_Resize_Images:\n",
    "        try:\n",
    "            file = Image.open(new_path_with_file)\n",
    "            width, height = file.size\n",
    "            \n",
    "            if file.size != (Crop_size, Crop_size):\n",
    "                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Å–∞–π–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π (center crop)\n",
    "                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ (–∫–≤–∞–¥—Ä–∞—Ç)\n",
    "                min_side = min(width, height)\n",
    "                \n",
    "                # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –∫–≤–∞–¥—Ä–∞—Ç–∞ (center crop)\n",
    "                left = (width - min_side) // 2\n",
    "                top = (height - min_side) // 2\n",
    "                right = left + min_side\n",
    "                bottom = top + min_side\n",
    "                \n",
    "                file_cropped = file.crop((left, top, right, bottom))\n",
    "                \n",
    "                # –†–µ—Å–∞–π–∑ –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞\n",
    "                file_resized = file_cropped.resize((Crop_size, Crop_size), Image.Resampling.LANCZOS)\n",
    "                \n",
    "                if extension.upper() in [\"JPG\", \"JPEG\"]:\n",
    "                    file_resized = file_resized.convert(\"RGB\")\n",
    "                    file_resized.save(new_path_with_file, format=\"JPEG\", quality=100)\n",
    "                else:\n",
    "                    file_resized.save(new_path_with_file, format=extension.upper())\n",
    "            \n",
    "            processed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {filename}: {e}\")\n",
    "    else:\n",
    "        processed_count += 1\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    os.chdir(INSTANCE_DIR)\n",
    "    subprocess.run(\"find . -name '* *' -type f | rename 's/ /-/g'\", shell=True, capture_output=True)\n",
    "    os.chdir(CAPTIONS_DIR)\n",
    "    subprocess.run(\"find . -name '* *' -type f | rename 's/ /-/g'\", shell=True, capture_output=True)\n",
    "    os.chdir('/content')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–æ–≤\n",
    "try:\n",
    "    os.chdir(SESSION_DIR)\n",
    "    subprocess.run(\"rm -f instance_images.zip captions.zip\", shell=True, capture_output=True)\n",
    "    subprocess.run(\"zip -r -q instance_images instance_images\", shell=True, capture_output=True)\n",
    "    subprocess.run(\"zip -r -q captions captions\", shell=True, capture_output=True)\n",
    "    os.chdir('/content')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# –ü–æ–¥—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "final_image_count = len([f for f in os.listdir(INSTANCE_DIR) \n",
    "                         if os.path.isfile(os.path.join(INSTANCE_DIR, f)) \n",
    "                         and f.split('.')[-1].lower() in ['jpg', 'jpeg', 'png', 'webp', 'bmp']])\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–ì–†–£–ñ–ï–ù–´\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {final_image_count}\")\n",
    "if caption_files:\n",
    "    print(f\"üìù –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ–¥–ø–∏—Å–µ–π: {len(caption_files)}\")\n",
    "print(f\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {INSTANCE_DIR}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if final_image_count < 5:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–µ–Ω—å—à–µ 5 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\")\n",
    "    print(\"–î–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: 10-20 —Ñ–æ—Ç–æ\")\n",
    "    print(\"–î–ª—è —Å—Ç–∏–ª–µ–π: 15-25 —Ñ–æ—Ç–æ\")\n",
    "    print(\"=\"*60)\n",
    "elif final_image_count >= 10:\n",
    "    print(\"\\n‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚û°Ô∏è  –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Å–ª–µ–¥—É—é—â–∏–º —è—á–µ–π–∫–∞–º –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QyvcqeiL65Tj"
   },
   "outputs": [],
   "source": [
    "#@title üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π { display-mode: \"form\" }\n",
    "\n",
    "from IPython.utils import capture\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é Python –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏\n",
    "python_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "python_packages_path = f\"/usr/local/lib/python{python_version}/dist-packages\"\n",
    "\n",
    "print(f'‚åõ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (5-10 –º–∏–Ω—É—Ç)...')\n",
    "print(f'üêç –û–±–Ω–∞—Ä—É–∂–µ–Ω Python {python_version}')\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "    os.chdir('/content')\n",
    "    !pip uninstall diffusers jax -qq -y\n",
    "    !pip install -qq --no-deps accelerate==0.12.0\n",
    "    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n",
    "    !dpkg -i *.deb\n",
    "    !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
    "    !rm *.deb | rm *.zst | rm *.txt\n",
    "    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
    "    !pip install gradio==3.16.2 -qq\n",
    "    !pip install wandb==0.15.12 pydantic==1.10.2 numpy==1.26 scipy==1.15.3 -qq --no-deps\n",
    "\n",
    "    if not os.path.exists('gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
    "        %env CXXFLAGS=-std=c++14\n",
    "        !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
    "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
    "        %cd /content/gperftools  \n",
    "        !patch -p1 < /content/Patch\n",
    "        !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
    "        !mkdir -p /content/gdrive/MyDrive/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/MyDrive/sd/libtcmalloc\n",
    "        %env LD_PRELOAD=/content/gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
    "        %cd /content\n",
    "        !rm *.tar.gz Patch && rm -r /content/gperftools\n",
    "    else:\n",
    "        %env LD_PRELOAD=/content/gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
    "\n",
    "    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏ Python\n",
    "    os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "    !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python$python_version/warnings.py\n",
    "    !sed -i 's@HfFolder, cached_download@HfFolder@g' $python_packages_path/diffusers/utils/dynamic_modules_utils.py\n",
    "    !sed -i 's@from pytorch_lightning.loggers.wandb import WandbLogger  # noqa: F401@@g' $python_packages_path/pytorch_lightning/loggers/__init__.py\n",
    "    !sed -i 's@from .mailbox import ContextCancelledError@@g' $python_packages_path/wandb/sdk/lib/retry.py\n",
    "    !sed -i 's@raise ContextCancelledError(\"retry timeout\")@print(\"retry timeout\")@g' $python_packages_path/wandb/sdk/lib/retry.py\n",
    "    !sed -i 's@globalns, localns, set()@globalns, localns, recursive_guard=set()@g' $python_packages_path/pydantic/typing.py\n",
    "    !rm -r $python_packages_path/tensorflow*\n",
    "\n",
    "print('‚úì –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3SsbIlxw66N"
   },
   "source": [
    "# üì• –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "O3KHGKqyeJp9"
   },
   "outputs": [],
   "source": [
    "#@title üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ { display-mode: \"form\" }\n",
    "\n",
    "import os\n",
    "import time\n",
    "from IPython.utils import capture\n",
    "from IPython.display import clear_output\n",
    "import wget\n",
    "from subprocess import check_output\n",
    "import urllib.request\n",
    "import requests\n",
    "import base64\n",
    "from gdown.download import get_url_from_gdrive_confirmation\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from urllib.request import urlopen, Request\n",
    "import re\n",
    "\n",
    "# ============================================\n",
    "# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò\n",
    "# ============================================\n",
    "\n",
    "def getsrc(url):\n",
    "    \"\"\"–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ URL\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.netloc == 'civitai.com':\n",
    "        return 'civitai'\n",
    "    elif parsed_url.netloc == 'drive.google.com':\n",
    "        return 'gdrive'\n",
    "    elif parsed_url.netloc == 'huggingface.co':\n",
    "        return 'huggingface'\n",
    "    else:\n",
    "        return 'others'\n",
    "\n",
    "def get_name(url, gdrive):\n",
    "    \"\"\"–ü–æ–ª—É—á–∞–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL\"\"\"\n",
    "    if not gdrive:\n",
    "        response = requests.get(url, allow_redirects=False)\n",
    "        if \"Location\" in response.headers:\n",
    "            redirected_url = response.headers[\"Location\"]\n",
    "            quer = parse_qs(urlparse(redirected_url).query)\n",
    "            if \"response-content-disposition\" in quer:\n",
    "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
    "                for vals in disp_val:\n",
    "                    if vals.strip().startswith(\"filename=\"):\n",
    "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
    "                        return filenm.replace(\"\\\"\",\"\")\n",
    "    else:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
    "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
    "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
    "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
    "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
    "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
    "        return filenm\n",
    "\n",
    "def detect_model_version(model_path, sftnsr=\"\"):\n",
    "    \"\"\"–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏\"\"\"\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
    "    print('üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏...')\n",
    "    version = check_output(f'python det.py {sftnsr} --MODEL_PATH {model_path}', shell=True).decode('utf-8').replace('\\n', '')\n",
    "    clear_output()\n",
    "    print(f'‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–µ—Ä—Å–∏—è: {version}')    \n",
    "    !rm det.py\n",
    "    return version\n",
    "\n",
    "def convert_model_to_diffusers(model_path, output_path, version, sftnsr=\"\"):\n",
    "    \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –≤ —Ñ–æ—Ä–º–∞—Ç diffusers\"\"\"\n",
    "    if version == '1.5':\n",
    "        !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
    "        !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$model_path\" --dump_path \"$output_path\" --original_config_file config.yaml $sftnsr\n",
    "        !rm config.yaml\n",
    "    elif version == 'V2.1-512px':\n",
    "        !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
    "        !python /content/convertodiff.py \"$model_path\" \"$output_path\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
    "        !rm convertodiff.py\n",
    "    elif version == 'V2.1-768px':\n",
    "        !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
    "        !python /content/convertodiff.py \"$model_path\" \"$output_path\" --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
    "        !rm convertodiff.py\n",
    "\n",
    "def download_sd15_base():\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å SD 1.5\"\"\"\n",
    "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
    "        !rm -r /content/stable-diffusion-v1-5\n",
    "    clear_output()\n",
    "    os.chdir('/content')\n",
    "    print(\"‚åõ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SD 1.5...\")\n",
    "    !wget -q \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" -O model.safetensors\n",
    "    \n",
    "    if os.path.exists('/content/model.safetensors'):\n",
    "        !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
    "        clear_output()\n",
    "        !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.safetensors --dump_path /content/stable-diffusion-v1-5 --original_config_file config.yaml --from_safetensors\n",
    "        !rm config.yaml\n",
    "        clear_output()\n",
    "        os.chdir('/content/stable-diffusion-v1-5')\n",
    "        !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
    "        !rm model_index.json\n",
    "        clear_output()\n",
    "        time.sleep(1)    \n",
    "        wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "        os.chdir('/content')\n",
    "\n",
    "def download_sd2_model(version):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å SD 2.x\"\"\"\n",
    "    folder_name = '/content/stable-diffusion-v2-768' if version == \"V2.1-768px\" else '/content/stable-diffusion-v2-512'\n",
    "    model_name = \"stabilityai/stable-diffusion-2-1\" if version == \"V2.1-768px\" else \"stabilityai/stable-diffusion-2-1-base\"\n",
    "    \n",
    "    os.chdir('/content')\n",
    "    clear_output()\n",
    "    !mkdir $folder_name\n",
    "    os.chdir(folder_name)\n",
    "    !git config --global init.defaultBranch main\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin \"https://huggingface.co/$model_name\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    !rm -r $folder_name/.git\n",
    "    os.chdir('/content')\n",
    "    clear_output()\n",
    "\n",
    "# ============================================\n",
    "# –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –ó–ê–ì–†–£–ó–ö–ò\n",
    "# ============================================\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n",
    "    with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n",
    "        token = f.read()\n",
    "    authe = f'https://USER:{token}@'\n",
    "else:\n",
    "    authe = \"https://\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"–ó–ê–ì–†–£–ó–ö–ê –ë–ê–ó–û–í–û–ô –ú–û–î–ï–õ–ò\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "MODEL_NAME = None\n",
    "\n",
    "try:\n",
    "    # 1. HuggingFace –º–æ–¥–µ–ª—å\n",
    "    if Path_to_HuggingFace != \"\":\n",
    "        print(f\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å HuggingFace: {Path_to_HuggingFace}\")\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é –ø–æ —Ä–∞–∑–º–µ—Ä—É text_encoder\n",
    "        if authe == \"https://\":\n",
    "            textenc = f\"{authe}huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
    "            txtenc_size = urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
    "        else:\n",
    "            textenc = f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
    "            req = urllib.request.Request(textenc)\n",
    "            req.add_header('Authorization', f'Bearer {token}')\n",
    "            txtenc_size = urllib.request.urlopen(req).info().get('Content-Length', None)\n",
    "        \n",
    "        is_v2 = int(txtenc_size) > 670000000\n",
    "        \n",
    "        if os.path.exists('/content/stable-diffusion-custom'):\n",
    "            !rm -r /content/stable-diffusion-custom\n",
    "        \n",
    "        os.chdir('/content')\n",
    "        clear_output()\n",
    "        print(f\"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å {'V2' if is_v2 else 'V1'}\")\n",
    "        \n",
    "        !mkdir /content/stable-diffusion-custom\n",
    "        os.chdir('/content/stable-diffusion-custom')\n",
    "        !git init\n",
    "        !git lfs install --system --skip-repo\n",
    "        !git remote add -f origin \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
    "        !git config core.sparsecheckout true\n",
    "        \n",
    "        if is_v2:\n",
    "            !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
    "        else:\n",
    "            !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
    "        \n",
    "        !git pull origin main\n",
    "        \n",
    "        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            !rm -r /content/stable-diffusion-custom/.git\n",
    "            if not is_v2:\n",
    "                !rm model_index.json\n",
    "                time.sleep(1)\n",
    "                wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "            os.chdir('/content')\n",
    "            MODEL_NAME = \"/content/stable-diffusion-custom\"\n",
    "            clear_output()\n",
    "            print('‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "        else:\n",
    "            print('‚ùå –û—à–∏–±–∫–∞: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É')\n",
    "            raise Exception(\"Model download failed\")\n",
    "    \n",
    "    # 2. –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (.ckpt/.safetensors)\n",
    "    elif MODEL_PATH != \"\":\n",
    "        print(f\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {MODEL_PATH}\")\n",
    "        modelname = os.path.basename(MODEL_PATH)\n",
    "        sftnsr = \"--from_safetensors\" if modelname.split('.')[-1] == 'safetensors' else \"\"\n",
    "        \n",
    "        os.chdir('/content')\n",
    "        clear_output()\n",
    "        \n",
    "        if os.path.exists(str(MODEL_PATH)):\n",
    "            version = detect_model_version(MODEL_PATH, sftnsr)\n",
    "            convert_model_to_diffusers(MODEL_PATH, '/content/stable-diffusion-custom', version, sftnsr)\n",
    "            \n",
    "            if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "                clear_output()\n",
    "                MODEL_NAME = \"/content/stable-diffusion-custom\"\n",
    "                print('‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "            else:\n",
    "                print('‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏')\n",
    "                raise Exception(\"Model conversion failed\")\n",
    "        else:\n",
    "            print('‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')\n",
    "            raise Exception(\"Model file not found\")\n",
    "    \n",
    "    # 3. –°—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å (Civitai, Google Drive)\n",
    "    elif MODEL_LINK != \"\":\n",
    "        print(f\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ —Å—Å—ã–ª–∫–µ...\")\n",
    "        os.chdir('/content')\n",
    "        src = getsrc(MODEL_LINK)\n",
    "        \n",
    "        if src == 'civitai':\n",
    "            modelname = get_name(str(MODEL_LINK), False)\n",
    "        elif src == 'gdrive':\n",
    "            modelname = get_name(str(MODEL_LINK), True)\n",
    "        else:\n",
    "            modelname = os.path.basename(str(MODEL_LINK))\n",
    "        \n",
    "        sftnsr = \"--from_safetensors\" if modelname.split('.')[-1] == 'safetensors' else \"\"\n",
    "        modelnm = \"model.safetensors\" if sftnsr else \"model.ckpt\"\n",
    "        \n",
    "        !gdown --fuzzy \"$MODEL_LINK\" -O $modelnm\n",
    "        \n",
    "        if os.path.exists(modelnm) and os.path.getsize(modelnm) > 1810671599:\n",
    "            version = detect_model_version(modelnm, sftnsr)\n",
    "            convert_model_to_diffusers(modelnm, '/content/stable-diffusion-custom', version, sftnsr)\n",
    "            \n",
    "            if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "                clear_output()\n",
    "                MODEL_NAME = \"/content/stable-diffusion-custom\"\n",
    "                print('‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞')\n",
    "            else:\n",
    "                print('‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏')\n",
    "                raise Exception(\"Model conversion failed\")\n",
    "        else:\n",
    "            print('‚ùå –û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –∏–ª–∏ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª')\n",
    "            raise Exception(\"Invalid model link\")\n",
    "    \n",
    "    # 4. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å\n",
    "    else:\n",
    "        if Model_Version == \"1.5\":\n",
    "            if not os.path.exists('/content/stable-diffusion-v1-5/unet'):\n",
    "                download_sd15_base()\n",
    "                MODEL_NAME = \"/content/stable-diffusion-v1-5\"\n",
    "                print(\"‚úì –ú–æ–¥–µ–ª—å SD v1.5 –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
    "            else:\n",
    "                MODEL_NAME = \"/content/stable-diffusion-v1-5\"\n",
    "                print(\"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –º–æ–¥–µ–ª—å SD v1.5\")\n",
    "        \n",
    "        elif Model_Version == \"V2.1-512px\":\n",
    "            if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
    "                download_sd2_model(\"V2.1-512px\")\n",
    "                MODEL_NAME = \"/content/stable-diffusion-v2-512\"\n",
    "                print(\"‚úì –ú–æ–¥–µ–ª—å SD v2-512px –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
    "            else:\n",
    "                MODEL_NAME = \"/content/stable-diffusion-v2-512\"\n",
    "                print(\"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –º–æ–¥–µ–ª—å SD v2-512px\")\n",
    "        \n",
    "        elif Model_Version == \"V2.1-768px\":\n",
    "            if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
    "                download_sd2_model(\"V2.1-768px\")\n",
    "                MODEL_NAME = \"/content/stable-diffusion-v2-768\"\n",
    "                print(\"‚úì –ú–æ–¥–µ–ª—å SD v2-768px –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
    "            else:\n",
    "                MODEL_NAME = \"/content/stable-diffusion-v2-768\"\n",
    "                print(\"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –º–æ–¥–µ–ª—å SD v2-768px\")\n",
    "\n",
    "    if MODEL_NAME:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"‚úì –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞: {MODEL_NAME}\")\n",
    "        print(\"=\" * 50)\n",
    "    else:\n",
    "        print(\"‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å\")\n",
    "        raise Exception(\"Model loading failed\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}\")\n",
    "    print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnmQYfZilzY6"
   },
   "source": [
    "# üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1-9QbkfAVYYU"
   },
   "outputs": [],
   "source": [
    "#@title üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏) { display-mode: \"form\" }\n",
    "\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from google.colab import runtime\n",
    "from subprocess import getoutput\n",
    "import time\n",
    "import random\n",
    "\n",
    "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "PT=\"\"\n",
    "MODELT_NAME=MODEL_NAME\n",
    "Res=int(Resolution)\n",
    "INSTANCE_NAME=Session_Name\n",
    "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "trnonltxt=\"\"\n",
    "if UNet_Training_Steps==0:\n",
    "   trnonltxt=\"--train_only_text_encoder\"\n",
    "\n",
    "Seed=random.randint(1, 999999)\n",
    "\n",
    "ofstnse=\"\"\n",
    "if Offset_Noise:\n",
    "  ofstnse=\"--offset_noise\"\n",
    "\n",
    "extrnlcptn=\"\"\n",
    "if External_Captions:\n",
    "  extrnlcptn=\"--external_captions\"\n",
    "\n",
    "fp16 = True\n",
    "precision=\"fp16\" if fp16 else \"no\"\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "V2=False\n",
    "if os.path.getsize(MODELT_NAME+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
    "  V2=True\n",
    "\n",
    "s = getoutput('nvidia-smi')\n",
    "GCUNET=\"--gradient_checkpointing\"\n",
    "TexRes=Res\n",
    "if Res<=768:\n",
    "  GCUNET=\"\"\n",
    "\n",
    "if V2:  \n",
    "  if Res>704:\n",
    "    GCUNET=\"--gradient_checkpointing\"\n",
    "  if Res>576:\n",
    "    TexRes=576\n",
    "\n",
    "if 'A100' in s :\n",
    "   GCUNET=\"\"\n",
    "   TexRes=Res\n",
    "\n",
    "Enable_text_encoder_training = True\n",
    "if Text_Encoder_Training_Steps==0 :\n",
    "   Enable_text_encoder_training = False\n",
    "else:\n",
    "  stptxt=Text_Encoder_Training_Steps\n",
    "\n",
    "# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "stp=0\n",
    "stpsv=Start_saving_from_the_step\n",
    "if Start_saving_from_the_step < 200:\n",
    "  stpsv=Save_Checkpoint_Every\n",
    "if Save_Checkpoint_Every_n_Steps:\n",
    "  stp=Save_Checkpoint_Every\n",
    "else:\n",
    "  stp=0\n",
    "  stpsv=0\n",
    "\n",
    "# –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è learning rate\n",
    "untlr=UNet_Learning_Rate\n",
    "txlr=Text_Encoder_Learning_Rate\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø DREAMBOOTH\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"–°–µ—Å—Å–∏—è: {Session_Name}\")\n",
    "print(f\"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {MODEL_NAME}\")\n",
    "print(f\"Seed: {Seed}\")\n",
    "print(\"-\" * 60)\n",
    "print(\"–ü–ê–†–ê–ú–ï–¢–†–´:\")\n",
    "print(f\"  UNet: {UNet_Training_Steps} —à–∞–≥–æ–≤, LR={UNet_Learning_Rate}\")\n",
    "print(f\"  Text Encoder: {Text_Encoder_Training_Steps} —à–∞–≥–æ–≤, LR={Text_Encoder_Learning_Rate}\")\n",
    "print(f\"  –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {Resolution}\")\n",
    "print(f\"  –¢–æ—á–Ω–æ—Å—Ç—å: {precision}\")\n",
    "if Save_Checkpoint_Every_n_Steps and stp > 0:\n",
    "    print(f\"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: {stp} —à–∞–≥–æ–≤ (–Ω–∞—á–∏–Ω–∞—è —Å {stpsv})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps, txlr, TexRes):\n",
    "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $trnonltxt \\\n",
    "    $extrnlcptn \\\n",
    "    $ofstnse \\\n",
    "    --image_captions_filename \\\n",
    "    --train_text_encoder \\\n",
    "    --dump_only_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$TexRes \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$txlr \\\n",
    "    --lr_scheduler=\"linear\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps, untlr, GCUNET):\n",
    "    clear_output()\n",
    "    print('üîÑ –û–±—É—á–µ–Ω–∏–µ UNet...')\n",
    "    \n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    save_params = \"\"\n",
    "    if stp > 0:\n",
    "        save_params = f\"--save_starting_step={stpsv} --save_n_steps={stp} --Session_dir={SESSION_DIR}\"\n",
    "    \n",
    "    cmd = f\"\"\"accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    {extrnlcptn} \\\n",
    "    {ofstnse} \\\n",
    "    --image_captions_filename \\\n",
    "    --train_only_unet \\\n",
    "    {save_params} \\\n",
    "    --pretrained_model_name_or_path=\"{MODELT_NAME}\" \\\n",
    "    --instance_data_dir=\"{INSTANCE_DIR}\" \\\n",
    "    --output_dir=\"{OUTPUT_DIR}\" \\\n",
    "    --captions_dir=\"{CAPTIONS_DIR}\" \\\n",
    "    --instance_prompt=\"{PT}\" \\\n",
    "    --seed={Seed} \\\n",
    "    --resolution={Res} \\\n",
    "    --mixed_precision={precision} \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 {GCUNET} \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate={untlr} \\\n",
    "    --lr_scheduler=\"linear\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps={Training_Steps}\"\"\"\n",
    "    \n",
    "    !{cmd}\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ Text Encoder\n",
    "if Enable_text_encoder_training:\n",
    "  print('üìù –®–∞–≥ 1/2: –û–±—É—á–µ–Ω–∏–µ Text Encoder...')\n",
    "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
    "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
    "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt, txlr=txlr, TexRes=TexRes)\n",
    "  print('‚úì Text Encoder –æ–±—É—á–µ–Ω\\n')\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ UNet\n",
    "if UNet_Training_Steps!=0:\n",
    "  print('üé® –®–∞–≥ 2/2: –û–±—É—á–µ–Ω–∏–µ UNet...')\n",
    "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps, untlr=untlr, GCUNET=GCUNET)\n",
    "  print('‚úì UNet –æ–±—É—á–µ–Ω\\n')\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CKPT\n",
    "if UNet_Training_Steps==0 and Text_Encoder_Training_Steps==0:\n",
    "  print('‚ùå –ù–µ—á–µ–≥–æ –æ–±—É—á–∞—Ç—å (–æ–±–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ = 0)')\n",
    "else:\n",
    "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
    "    print('üíæ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç .ckpt...')\n",
    "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
    "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
    "    clear_output()\n",
    "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
    "      clear_output()\n",
    "      print(\"\\n\" + \"=\" * 60)\n",
    "      print(\"üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!\")\n",
    "      print(\"=\" * 60)\n",
    "      print(f\"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {Session_Name}.ckpt\")\n",
    "      print(f\"‚úì –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: Google Drive/Fast-Dreambooth/Sessions/{Session_Name}/\")\n",
    "      print(\"\\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ –ø—Ä–æ–º–ø—Ç–∞—Ö:\")\n",
    "      print(f\"  sksper person, portrait, high quality\")\n",
    "      print(\"=\" * 60)\n",
    "      \n",
    "      if Disconnect_after_training:\n",
    "        print(\"\\n‚è∞ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 20 —Å–µ–∫—É–Ω–¥...\")\n",
    "        time.sleep(20)\n",
    "        runtime.unassign()\n",
    "    else:\n",
    "      print(\"=\" * 60)\n",
    "      print(\"‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å .ckpt —Ñ–∞–π–ª\")\n",
    "      print(\"=\" * 60)\n",
    "  else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚ùå –û–®–ò–ë–ö–ê: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞\")\n",
    "    print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —à–∞–≥–∏\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n",
    "\n",
    "### –ì–¥–µ –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å\n",
    "–í–∞—à–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–∞ Google Drive:\n",
    "```\n",
    "Google Drive/Fast-Dreambooth/Sessions/[–Ω–∞–∑–≤–∞–Ω–∏–µ_—Å–µ—Å—Å–∏–∏]/[–Ω–∞–∑–≤–∞–Ω–∏–µ_—Å–µ—Å—Å–∏–∏].ckpt\n",
    "```\n",
    "\n",
    "### –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "\n",
    "#### –í Automatic1111 WebUI:\n",
    "1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ `.ckpt` —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É `models/Stable-diffusion/`\n",
    "2. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ WebUI\n",
    "3. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ\n",
    "\n",
    "#### –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤:\n",
    "```\n",
    "sksper person, professional photo, high quality\n",
    "sksper person wearing sunglasses, outdoor\n",
    "sksper person as a superhero, digital art\n",
    "sksper person, oil painting style\n",
    "```\n",
    "\n",
    "### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏\n",
    "- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã\n",
    "- **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ**: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ checkpoint'—ã (–µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è–ª–∏—Å—å)\n",
    "- **–£–ª—É—á—à–µ–Ω–∏–µ**: –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –∏–¥–µ–∞–ª–µ–Ω:\n",
    "  - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —è—á–µ–π–∫—É —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏\n",
    "  - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `Resume_Training = True` –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö\n",
    "  - –î–æ–±–∞–≤—å—Ç–µ 300-500 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —à–∞–≥–æ–≤\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "bbKbx185zqlz",
    "AaLtXBbPleBr"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
